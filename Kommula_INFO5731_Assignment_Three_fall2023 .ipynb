{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/unt-iialab/INFO5731_Spring2020/blob/master/Assignments/INFO5731_Assignment_Three.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USSdXHuqnwv9"
   },
   "source": [
    "# **INFO5731 Assignment Three**\n",
    "\n",
    "In this assignment, you are required to conduct information extraction, semantic analysis based on **the dataset you collected from assignment two**. You may use scipy and numpy package in this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWxodXh5n4xF"
   },
   "source": [
    "# **Question 1: Understand N-gram**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TenBkDJ5n95k"
   },
   "source": [
    "(45 points). Write a python program to conduct N-gram analysis based on the dataset in your assignment two:\n",
    "\n",
    "(1) Count the frequency of all the N-grams (N=3).\n",
    "\n",
    "(2) Calculate the probabilities for all the bigrams in the dataset by using the fomular count(w2 w1) / count(w2). For example, count(really like) / count(really) = 1 / 3 = 0.33.\n",
    "\n",
    "(3) Extract all the **noun phrases** and calculate the relative probabilities of each review in terms of other reviews (abstracts, or tweets) by using the fomular frequency (noun phrase) / max frequency (noun phrase) on the whole dataset. Print out the result in a table with column name the all the noun phrases and row name as all the 100 reviews (abstracts, or tweets).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PuFPKhC0m1fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Review'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataset= pd.read_csv('amazon_product_reviews.csv')\n",
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk import ngrams, word_tokenize, pos_tag\n",
    "from collections import Counter\n",
    "\n",
    "# Load the dataset (replace 'path/to/your/dataset.csv' with the actual path)\n",
    "df_reviews = pd.read_csv('amazon_product_reviews.csv')\n",
    "\n",
    "# Function to tokenize and get N-grams\n",
    "def get_ngrams(text, n):\n",
    "    tokens = word_tokenize(text)\n",
    "    n_grams = ngrams(tokens, n)\n",
    "    return list(n_grams)\n",
    "\n",
    "# Step 1: Count the frequency of all the N-grams (N=3)\n",
    "all_ngrams = [ngram for review_text in df_reviews['Review'] for ngram in get_ngrams(review_text, 3)]\n",
    "ngram_counts = Counter(all_ngrams)\n",
    "\n",
    "# Step 2: Calculate the probabilities for all bigrams\n",
    "bigram_probabilities = {}\n",
    "for bigram in all_ngrams:\n",
    "    denominator = ngram_counts[bigram[:-1]]\n",
    "    bigram_probabilities[bigram] = ngram_counts[bigram] / denominator if denominator != 0 else 0\n",
    "\n",
    "# Step 3: Extract noun phrases and calculate relative probabilities\n",
    "def extract_noun_phrases(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    noun_phrases = [chunk[0] for chunk in tagged_tokens if 'NN' in chunk[1]]\n",
    "    return noun_phrases\n",
    "\n",
    "all_noun_phrases = [noun_phrase for review_text in df_reviews['Review'] for noun_phrase in extract_noun_phrases(review_text)]\n",
    "noun_phrase_counts = Counter(all_noun_phrases)\n",
    "max_counts = {noun_phrase: max(noun_phrase_counts.values()) for noun_phrase in noun_phrase_counts}\n",
    "\n",
    "# Creating a table with relative probabilities\n",
    "result_table = pd.DataFrame(index=df_reviews.index, columns=noun_phrase_counts.keys())\n",
    "for i, review_text in enumerate(df_reviews['Review']):\n",
    "    noun_phrases_in_text = extract_noun_phrases(review_text)\n",
    "    for noun_phrase in noun_phrase_counts.keys():\n",
    "        result_table.at[i, noun_phrase] = noun_phrases_in_text.count(noun_phrase) / max_counts[noun_phrase]\n",
    "\n",
    "# Print the result table\n",
    "print(result_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfpMRCrRwN6Z"
   },
   "source": [
    "# **Question 2: Undersand TF-IDF and Document representation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dCQEbDawWCw"
   },
   "source": [
    "(20 points). Starting from the documents (all the reviews, or abstracts, or tweets) collected for assignment two, write a python program:\n",
    "\n",
    "(1) To build the **documents-terms weights (tf*idf) matrix bold text**.\n",
    "\n",
    "(2) To rank the documents with respect to query (design a query by yourself, for example, \"An Outstanding movie with a haunting performance and best character development\") by using **cosine similarity**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vATjQNTY8buA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/bhanuprasadkommula/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/bhanuprasadkommula/anaconda3/lib/python3.11/site-packages (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/bhanuprasadkommula/anaconda3/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/bhanuprasadkommula/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/bhanuprasadkommula/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/bhanuprasadkommula/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 7)) while a minimum of 1 is required by check_pairwise_arrays.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe tfidf_matrix has zero samples. Please check your data and preprocessing.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Compute cosine similarity between the query and reviews\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m cosine_similarities \u001b[38;5;241m=\u001b[39m cosine_similarity(tfidf_matrix[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], tfidf_matrix[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Create a DataFrame to store the results\u001b[39;00m\n\u001b[1;32m     35\u001b[0m results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReviewID\u001b[39m\u001b[38;5;124m'\u001b[39m: df\u001b[38;5;241m.\u001b[39mindex,\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCosineSimilarity\u001b[39m\u001b[38;5;124m'\u001b[39m: cosine_similarities[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     38\u001b[0m })\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1577\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1543\u001b[0m \n\u001b[1;32m   1544\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;124;03m    Returns the cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1574\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1575\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m-> 1577\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[1;32m   1579\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:173\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    166\u001b[0m         X,\n\u001b[1;32m    167\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m     Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m    174\u001b[0m         Y,\n\u001b[1;32m    175\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m    176\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    177\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    178\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m    179\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    180\u001b[0m     )\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:969\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m--> 969\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    970\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    971\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    972\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    973\u001b[0m         )\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    976\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 7)) while a minimum of 1 is required by check_pairwise_arrays."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the IMDb reviews dataset\n",
    "df = pd.read_csv('amazon_product_reviews.csv')\n",
    "\n",
    "# Sample query (replace with your own query)\n",
    "query = \"Outstanding movie with great character development and brilliant acting\"\n",
    "\n",
    "# Check for missing values\n",
    "if df['Review'].isnull().any():\n",
    "    raise ValueError(\"There are missing values in the 'Review' column. Please handle or remove them.\")\n",
    "\n",
    "# Check if the 'Review' column contains text data\n",
    "if not df['Review'].apply(lambda x: isinstance(x, str)).all():\n",
    "    raise ValueError(\"The 'Review' column does not contain valid text data.\")\n",
    "\n",
    "# Combine the query with the existing reviews\n",
    "reviews = df['Review'].tolist()\n",
    "reviews.append(query)\n",
    "\n",
    "# Use TfidfVectorizer to build the tf*idf matrix\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(reviews)\n",
    "\n",
    "# Check if the tfidf_matrix has samples\n",
    "if tfidf_matrix.shape[0] == 0:\n",
    "    raise ValueError(\"The tfidf_matrix has zero samples. Please check your data and preprocessing.\")\n",
    "\n",
    "# Compute cosine similarity between the query and reviews\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results = pd.DataFrame({\n",
    "    'ReviewID': df.index,\n",
    "    'CosineSimilarity': cosine_similarities[0]\n",
    "})\n",
    "\n",
    "# Sort the reviews based on cosine similarity\n",
    "results = results.sort_values(by='CosineSimilarity', ascending=False)\n",
    "\n",
    "# Display the ranked reviews\n",
    "print(\"Ranked Reviews:\")\n",
    "print(results[['ReviewID', 'CosineSimilarity']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwxG2sB8emrv"
   },
   "source": [
    "# **Question 3: Create your own word embedding model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-si4QyU5emrw"
   },
   "source": [
    "(20 points). Use the data you collected for assignment two to build a word embedding model:\n",
    "\n",
    "(1) Train a 300-dimension word embedding (it can be word2vec, glove, ulmfit, bert, or others).\n",
    "\n",
    "(2) Visualize the word embedding model you created.\n",
    "\n",
    "Reference: https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
    "\n",
    "Reference: https://jaketae.github.io/study/word2vec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "kKsTClzYemrw"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/bhanuprasadkommula/anaconda3/lib/python3.11/site-packages (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/bhanuprasadkommula/anaconda3/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/bhanuprasadkommula/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/bhanuprasadkommula/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/bhanuprasadkommula/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data collected for assignment two (replace with your data)\n",
    "df = pd.read_csv('baahubali_reviews.csv')\n",
    "\n",
    "# Tokenize the text into sentences\n",
    "text = [str(sentence).split() for sentence in df['user_review']]\n",
    "\n",
    "# Train a Word2Vec model\n",
    "embedding_model = Word2Vec(text, vector_size=300, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Visualize the word embeddings using t-SNE\n",
    "def visualize_embeddings(model):\n",
    "    words = list(model.wv.index_to_key)\n",
    "    word_vectors = model.wv[words]\n",
    "\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    embeddings_2d = tsne.fit_transform(word_vectors)\n",
    "\n",
    "    df_embeddings = pd.DataFrame(embeddings_2d, columns=['X', 'Y'])\n",
    "    df_embeddings['Word'] = words\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.scatterplot(x='X', y='Y', data=df_embeddings, hue='Word', palette='viridis', alpha=0.7)\n",
    "    plt.title('Word Embedding Visualization')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the embeddings\n",
    "visualize_embeddings(embedding_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5mmYIfN8eYV"
   },
   "source": [
    "# **Question 4: Create your own training and evaluation data for sentiment analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsi2y4z88ngX"
   },
   "source": [
    "(15 points). **You dodn't need to write program for this question!** Read each review (abstract or tweet) you collected in detail, and annotate each review with a sentiment (positive, negative, or neutral). Save the annotated dataset into a csv file with three columns (first column: document_id, clean_text, sentiment), upload the csv file to GitHub and submit the file link blew. This datset will be used for assignment four: sentiment analysis and text classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XfvMKJjIXS5G"
   },
   "outputs": [],
   "source": [
    "# The GitHub link of your final csv file\n",
    "\n",
    "\n",
    "\n",
    "# Link:\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
